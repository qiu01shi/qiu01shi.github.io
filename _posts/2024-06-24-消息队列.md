---
layout: post
title: 消息队列
date: 2024-06-24 14:15 +0800
categories: [Kafka, 消息队列]
author: <author_id>  
---

# 00 消息队列学习

<img src="https://cdn.nlark.com/yuque/0/2024/png/29452643/1716042692482-da291d54-7109-4b5a-944a-f12d557b97cd.png" alt="img" style="zoom:70%;" />



消息队列的最佳学习资料就是它们的 **官方文档**，因为官方文档更加详细准确，并且随着版本迭代，很多第三方教程文档会过时，而官方文档总能保持与当前版本同步更新。以下是几个开源消息队列的官方文档：


几个开源消息队列的官方文档：

RocketMQ 官方文档： https://rocketmq.apache.org/docs/quick-start/

RocketMQ 中国开发者中心：http://rocketmq.cloud/zh-cn/ 

Kafka 官方文档： http://kafka.apache.org/documentation/

RabbitMQ 官方文档： https://www.rabbitmq.com/documentation.html

在使用消息队列的过程中，如果遇到问题，要善用搜索引擎，我推荐你首选 Google，次之是 Stack Overflow，相对而言，这些搜索引擎搜索到有价值信息的概率会更高一些。

Stack Overflow：https://stackoverflow.com/



# 01 为什么需要消息队列？

消息队列是最古老的中间件之一，从系统之间有通信需求开始，就自然产生了消息队列。但是给消息队列下一个准确的定义却不太容易。我们知道，**消息队列的主要功能就是收发消息**，但是它的作用不仅仅只是解决应用之间的通信问题这么简单。

**哪些问题适合使用消息队列来解决？**

## 1. 异步处理

大多数程序员在面试中，应该都问过或被问过一个经典却没有标准答案的问题：**如何设计一个秒杀系统？**这个问题可以有一百个版本的合理答案，但大多数答案中都离不开消息队列。

**秒杀系统需要解决的核心问题是，如何利用有限的服务器资源，尽可能多地处理短时间内的海量请求**。我们知道，处理一个秒杀请求包含了很多步骤，例如：

- 风险控制；
- 库存锁定；
- 生成订单；
- 短信通知；
- 更新统计数据。

如果没有任何优化，正常的处理流程是：App 将请求发送给网关，依次调用上述 5 个流程，然后将结果返回给 APP。


​		对于这 5 个步骤来说，能否决定秒杀成功，实际上只有 **风险控制** 和 **库存锁定** 这 2 个步骤。只要用户的秒杀请求通过风险控制，并在服务端完成库存锁定，就可以给用户返回秒杀结果了，对于后续的生成订单、短信通知和更新统计数据等步骤，并不一定要在秒杀请求中处理完成。

所以当服务端完成前面 2 个步骤，确定本次请求的秒杀结果后，就可以马上给用户返回响应，然后把请求的数据放入消息队列中，由消息队列异步地进行后续的操作。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716043404870-56509290-0888-4f30-85b6-36c3b399609d.png" alt="image.png" style="zoom:50%;" />

处理一个秒杀请求，从 5 个步骤减少为 2 个步骤，这样不仅响应速度更快，并且在秒杀期间，我们可以把大量的服务器资源用来处理秒杀请求。秒杀结束后再把资源用于处理后面的步骤，充分利用有限的服务器资源处理更多的秒杀请求。

**可以看到，在这个场景中，消息队列被用于实现服务的异步处理。**这样做的好处是：

- 可以更快地返回结果；
- 减少等待，自然实现了步骤之间的并发，提升系统总体的性能。



## 2. 流量控制

继续说我们的秒杀系统，我们已经使用消息队列实现了部分工作的异步处理，但我们还面临一个问题：**如何避免过多的请求压垮我们的秒杀系统？**

一个设计健壮的程序有自我保护的能力，也就是说，它应该可以在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了的请求并且保证自身运行正常。不幸的是，现实中很多程序并没有那么“健壮”，而直接拒绝请求返回错误对于用户来说也是不怎么好的体验。

因此，我们需要设计一套足够健壮的架构来将后端的服务保护起来。**我们的设计思路是，使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。**

加入消息队列后，整个秒杀流程变为：

1. 网关在收到请求后，将请求放入请求消息队列；
2. 后端服务从请求消息队列中获取 APP 请求，完成后续秒杀处理过程，然后返回结果。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716043724469-c3174f90-a213-435c-af73-10c297369067.webp" alt="img" style="zoom:20%;" />

秒杀开始后，当短时间内大量的秒杀请求到达网关时，不会直接冲击到后端的秒杀服务，而是先堆积在消息队列中，后端服务按照自己的最大处理能力，从消息队列中消费请求进行处理。

对于超时的请求可以直接丢弃，APP 将超时无响应的请求处理为秒杀失败即可。运维人员还可以随时增加秒杀服务的实例数量进行水平扩容，而不用对系统的其他部分做任何更改。



这种设计的 **优点** 是：能根据下游的处理能力自动调节流量，达到“削峰填谷”的作用。但这样做同样是有代价的：

- 增加了系统调用链环节，导致总体的响应时延变长。
- 上下游系统都要将同步调用改为异步消息，增加了系统的复杂度。





