---
title: 消息队列
author: <author_id>  
date: 2024-06-24 14:15 +0800
categories: [Kafka, 消息队列]
layout: post
---

## 00 消息队列学习

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716042692482-da291d54-7109-4b5a-944a-f12d557b97cd.png" alt="img" style="zoom:70%;" />



消息队列的最佳学习资料就是它们的 **官方文档**，因为官方文档更加详细准确，并且随着版本迭代，很多第三方教程文档会过时，而官方文档总能保持与当前版本同步更新。以下是几个开源消息队列的官方文档：


几个开源消息队列的官方文档：

RocketMQ 官方文档： https://rocketmq.apache.org/docs/quick-start/

RocketMQ 中国开发者中心：http://rocketmq.cloud/zh-cn/ 

Kafka 官方文档： http://kafka.apache.org/documentation/

RabbitMQ 官方文档： https://www.rabbitmq.com/documentation.html

在使用消息队列的过程中，如果遇到问题，要善用搜索引擎，我推荐你首选 Google，次之是 Stack Overflow，相对而言，这些搜索引擎搜索到有价值信息的概率会更高一些。

Stack Overflow：https://stackoverflow.com/



## 01 为什么需要消息队列？

消息队列是最古老的中间件之一，从系统之间有通信需求开始，就自然产生了消息队列。但是给消息队列下一个准确的定义却不太容易。我们知道，**消息队列的主要功能就是收发消息**，但是它的作用不仅仅只是解决应用之间的通信问题这么简单。

**哪些问题适合使用消息队列来解决？**

### 1. 异步处理

大多数程序员在面试中，应该都问过或被问过一个经典却没有标准答案的问题：**如何设计一个秒杀系统？**这个问题可以有一百个版本的合理答案，但大多数答案中都离不开消息队列。

**秒杀系统需要解决的核心问题是，如何利用有限的服务器资源，尽可能多地处理短时间内的海量请求**。我们知道，处理一个秒杀请求包含了很多步骤，例如：

- 风险控制；
- 库存锁定；
- 生成订单；
- 短信通知；
- 更新统计数据。

如果没有任何优化，正常的处理流程是：App 将请求发送给网关，依次调用上述 5 个流程，然后将结果返回给 APP。


​		对于这 5 个步骤来说，能否决定秒杀成功，实际上只有 **风险控制** 和 **库存锁定** 这 2 个步骤。只要用户的秒杀请求通过风险控制，并在服务端完成库存锁定，就可以给用户返回秒杀结果了，对于后续的生成订单、短信通知和更新统计数据等步骤，并不一定要在秒杀请求中处理完成。

所以当服务端完成前面 2 个步骤，确定本次请求的秒杀结果后，就可以马上给用户返回响应，然后把请求的数据放入消息队列中，由消息队列异步地进行后续的操作。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716043404870-56509290-0888-4f30-85b6-36c3b399609d.png" alt="image.png" style="zoom:50%;" />

处理一个秒杀请求，从 5 个步骤减少为 2 个步骤，这样不仅响应速度更快，并且在秒杀期间，我们可以把大量的服务器资源用来处理秒杀请求。秒杀结束后再把资源用于处理后面的步骤，充分利用有限的服务器资源处理更多的秒杀请求。

**可以看到，在这个场景中，消息队列被用于实现服务的异步处理。**这样做的好处是：

- 可以更快地返回结果；
- 减少等待，自然实现了步骤之间的并发，提升系统总体的性能。



### 2. 流量控制

继续说我们的秒杀系统，我们已经使用消息队列实现了部分工作的异步处理，但我们还面临一个问题：**如何避免过多的请求压垮我们的秒杀系统？**

一个设计健壮的程序有自我保护的能力，也就是说，它应该可以在海量的请求下，还能在自身能力范围内尽可能多地处理请求，拒绝处理不了的请求并且保证自身运行正常。不幸的是，现实中很多程序并没有那么“健壮”，而直接拒绝请求返回错误对于用户来说也是不怎么好的体验。

因此，我们需要设计一套足够健壮的架构来将后端的服务保护起来。**我们的设计思路是，使用消息队列隔离网关和后端服务，以达到流量控制和保护后端服务的目的。**

加入消息队列后，整个秒杀流程变为：

1. 网关在收到请求后，将请求放入请求消息队列；
2. 后端服务从请求消息队列中获取 APP 请求，完成后续秒杀处理过程，然后返回结果。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716043724469-c3174f90-a213-435c-af73-10c297369067.webp" alt="img" style="zoom:20%;" />

秒杀开始后，当短时间内大量的秒杀请求到达网关时，不会直接冲击到后端的秒杀服务，而是先堆积在消息队列中，后端服务按照自己的最大处理能力，从消息队列中消费请求进行处理。

对于超时的请求可以直接丢弃，APP 将超时无响应的请求处理为秒杀失败即可。运维人员还可以随时增加秒杀服务的实例数量进行水平扩容，而不用对系统的其他部分做任何更改。



这种设计的 **优点** 是：能根据下游的处理能力自动调节流量，达到“削峰填谷”的作用。但这样做同样是有代价的：

- 增加了系统调用链环节，导致总体的响应时延变长。
- 上下游系统都要将同步调用改为异步消息，增加了系统的复杂度。



那还有没有更简单一点儿的流量控制方法呢？如果我们能预估出秒杀服务的处理能力，就可以用消息队列实现一个令牌桶，更简单地进行流量控制。

**令牌桶控制流量** 的原理是：单位时间内只发放固定数量的令牌到令牌桶中，规定服务在处理请求之前必须先从令牌桶中拿出一个令牌，如果令牌桶中没有令牌，则拒绝请求。这样就保证单位时间内，能处理的请求不超过发放令牌的数量，起到了流量控制的作用。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716043725010-04797095-afdc-4903-a600-a3e3ab370722.webp" alt="image.png" style="zoom:20%;" />

实现的方式也很简单，不需要破坏原有的调用链，只要网关在处理 APP 请求时增加一个获取令牌的逻辑。

令牌桶可以简单地用一个有固定容量的消息队列加一个“令牌发生器”来实现：令牌发生器按照预估的处理能力，匀速生产令牌并放入令牌队列（如果队列满了则丢弃令牌），网关在收到请求时去令牌队列消费一个令牌，获取到令牌则继续调用后端秒杀服务，如果获取不到令牌则直接返回秒杀失败。



以上是常用的使用消息队列两种进行流量控制的设计方法，可以根据各自的优缺点和不同的适用场景进行合理选择。



### 3. 服务解耦

消息队列的另外一个作用，就是实现系统应用之间的解耦。再举一个电商的例子来说明 **解耦的作用和必要性**。

我们知道订单是电商系统中比较核心的数据，当一个新订单创建时：

1. 支付系统需要发起支付流程；
2. 风控系统需要审核订单的合法性；
3. 客服系统需要给用户发短信告知用户；
4. 经营分析系统需要更新统计数据；
5. ……

这些订单下游的系统都需要实时获得订单数据。随着业务不断发展，这些订单下游系统不断的增加，不断变化，并且每个系统可能只需要订单数据的一个子集，负责订单服务的开发团队不得不花费很大的精力，应对不断增加变化的下游系统，不停地修改调试订单系统与这些下游系统的接口。任何一个下游系统接口变更，都需要订单模块重新进行一次上线，对于一个电商的核心服务来说，这几乎是不可接受的。

所有的电商都选择 **用消息队列来解决类似的系统耦合过于紧密的问题**。引入消息队列后，订单服务在订单变化时发送一条消息到消息队列的一个主题 Order 中，所有下游系统都订阅主题 Order，这样每个下游系统都可以获得一份实时完整的订单数据。

无论增加、减少下游系统或是下游系统需求如何变化，订单服务都无需做任何更改，实现了订单服务与下游服务的解耦。

### 4. 小结

以上就是消息队列最常被使用的三种场景：**异步处理**、**流量控制** 和 **服务解耦**。当然，消息队列的适用范围不仅仅局限于这些场景，还有包括：

- 作为发布 / 订阅系统实现一个微服务级系统间的观察者模式；
- 连接流计算任务和数据；
- 用于将消息广播给大量接收者。



简单的说，我们在单体应用里面需要用队列解决的问题，在分布式系统中大多都可以用消息队列来解决。

同时我们也要认识到，消息队列也有它自身的一些问题和局限性，包括：

- 引入消息队列带来的延迟问题；
- 增加了系统的复杂度；
- 能产生数据不一致的问题。



所以我们说没有最好的架构，只有最适合的架构，根据目标业务的特点和自身条件选择合适的架构，才是体现一个架构师功力的地方。



## 02 该如何选择消息队列？

### 1. 选择消息队列产品的基本标准

虽然这些消息队列产品在功能和特性方面各有优劣，但我们在选择的时候要有一个 **最低标准**，保证入选的产品至少是及格的。

接下来我们先说一下这 **及格的标准** 是什么样的。

首先，必须是 **开源的产品**，这个非常重要。开源意味着，如果有一天你使用的消息队列遇到了一个影响你系统业务的 Bug，你至少还有机会通过修改源代码来迅速修复或规避这个 Bug，解决你的系统火烧眉毛的问题，而不是束手无策地等待开发者不一定什么时候发布的下一个版本来解决。

其次，这个产品必须是 **近年来比较流行并且有一定社区活跃度的产品**。流行的好处是，只要你的使用场景不太冷门，你遇到 Bug 的概率会非常低，因为大部分你可能遇到的 Bug，其他人早就遇到并且修复了。你在使用过程中遇到的一些问题，也比较容易在网上搜索到类似的问题，然后很快的找到解决方案。

还有一个优势就是，流行的产品 **与周边生态系统会有一个比较好的集成和兼容**，比如，Kafka 和 Flink 就有比较好的兼容性，Flink 内置了 Kafka 的 Data Source，使用 Kafka 就很容易作为 Flink 的数据源开发流计算应用，如果你用一个比较小众的消息队列产品，在进行流计算的时候，你就不得不自己开发一个 Flink 的 Data Source。

最后，作为一款及格的消息队列产品，必须具备的 **几个特性包括**：

- **消息的可靠传递**：确保不丢消息；
- **Cluster**：支持集群，确保不会因为某个节点宕机导致服务不可用，当然也不能丢消息；
- **性能**：具备足够好的性能，能满足绝大多数场景的性能要求。



接下来我们一起看一下有哪些符合上面这些条件，可供选择的开源消息队列产品。



### 2. 可供选择的消息队列产品

#### 2.1. RabbitMQ

首先，我们说一下老牌儿消息队列 RabbitMQ，俗称兔子 MQ。RabbitMQ 是使用一种比较小众的编程语言：`Erlang` 语言编写的，它最早是 **为电信行业系统之间的可靠通信设计的**，也是少数几个支持 **AMQP** 协议的消息队列之一。

RabbitMQ 就像它的名字中的兔子一样：**轻量级**、**迅捷**，它的 Slogan，也就是宣传口号，也很明确地表明了 RabbitMQ 的特点：Messaging that just works，“开箱即用的消息队列”。也就是说，**RabbitMQ 是一个相当轻量级的消息队列，非常容易部署和使用。**

另外 RabbitMQ 还号称是世界上使用最广泛的开源消息队列，是不是真的使用率世界第一，我们没有办法统计，但至少是“最流行的消息中间之一”，这是没有问题的。

RabbitMQ 一个比较有特色的功能是 **支持非常灵活的路由配置**，和其他消息队列不同的是，它在生产者（Producer）和队列（Queue）之间增加了一个 `Exchange` 模块，可以理解为交换机。

这个 Exchange 模块的作用和交换机也非常相似，**根据配置的路由规则将生产者发出的消息分发到不同的队列中**。路由的规则也非常灵活，甚至你可以自己来实现路由规则。基于这个 `Exchange`，可以产生很多的玩儿法，如果你正好需要这个功能，RabbitMQ 是个不错的选择。

**RabbitMQ 的客户端支持的编程语言大概是所有消息队列中最多的**，如果你的系统是用某种冷门语言开发的，那你多半可以找到对应的 RabbitMQ 客户端。



接下来说下 **RabbitMQ 的几个问题**。

**第一个问题** 是，RabbitMQ **对消息堆积的支持并不好**，在它的设计理念里面，消息队列是一个管道，大量的消息积压是一种不正常的情况，应当尽量去避免。当大量消息积压的时候，会导致 RabbitMQ 的性能急剧下降。

**第二个问题** 是，RabbitMQ 的 **性能是我们介绍的这几个消息队列中最差的**，根据官方给出的测试数据综合我们日常使用的经验，依据硬件配置的不同，它 **大概每秒钟可以处理几万到十几万条消息**。其实，这个性能也足够支撑绝大多数的应用场景了，不过，如果你的应用对消息队列的性能要求非常高，那不要选择 RabbitMQ。

**最后一个问题** 是 RabbitMQ 使用的编程语言 Erlang，这个编程语言不仅是非常小众的语言，更麻烦的是，这个语言的学习曲线非常陡峭。大多数流行的编程语言，比如 Java、C/C++、Python 和 JavaScript，虽然语法、特性有很多的不同，但它们基本的体系结构都是一样的，你只精通一种语言，也很容易学习其他的语言，短时间内即使做不到精通，但至少能达到“会用”的水平。



就像一个以英语为母语的人，学习法语、德语都很容易，但是你要是让他去学汉语，那基本上和学习其他这些语言不是一个难度级别的。很不幸的是，Erlang 就是编程语言中的“汉语”。所以如果你想基于 RabbitMQ 做一些扩展和二次开发什么的，建议你慎重考虑一下可持续维护的问题。



#### 2.2. RocketMQ

`RocketMQ` 是阿里巴巴在 2012 年开源的消息队列产品，后来捐赠给 Apache 软件基金会，2017 正式毕业，成为 Apache 的顶级项目。阿里内部也是使用 RocketMQ 作为支撑其业务的消息队列，经历过多次“双十一”考验，它的性能、稳定性和可靠性都是值得信赖的。作为优秀的国产消息队列，近年来越来越多的被国内众多大厂使用。

我在总结 RocketMQ 的特点时，发现很难找出 RocketMQ 有什么特别让我印象深刻的特点，也很难找到它有什么缺点。

RocketMQ 就像一个品学兼优的好学生，**有着不错的性能，稳定性和可靠性**，具备一个现代的消息队列应该有的几乎全部功能和特性，并且它还在持续的成长中。

RocketMQ 有非常活跃的中文社区，大多数问题你都可以找到中文的答案，也许会成为你选择它的一个原因。另外，RocketMQ 使用 Java 语言开发，它的贡献者大多数都是中国人，源代码相对也比较容易读懂，你很容易对 RocketMQ 进行扩展或者二次开发。

RocketMQ 对在线业务的响应时延做了很多的优化，大多数情况下可以做到毫秒级的响应，**如果你的应用场景很在意响应时延，那应该选择使用 RocketMQ。**

RocketMQ 的性能比 RabbitMQ 要高一个数量级，**每秒钟大概能处理几十万条消息**。

RocketMQ 的一个劣势是，作为国产的消息队列，相比国外的比较流行的同类产品，在国际上还没有那么流行，与周边生态系统的集成和兼容程度要略逊一筹。



#### 2.3. Kafka

最后我们聊一聊 Kafka。Kafka 最早是由 LinkedIn 开发，目前也是 Apache 的顶级项目。**Kafka 最初的设计目的是用于处理海量的日志**。

在早期的版本中，为了获得极致的性能，在设计方面做了很多的牺牲，比如不保证消息的可靠性，可能会丢失消息，也不支持集群，功能上也比较简陋，这些牺牲对于处理海量日志这个特定的场景都是可以接受的。这个时期的 Kafka 甚至不能称之为一个合格的消息队列。

但是，请注意，重点一般都在后面。随后的几年 Kafka 逐步补齐了这些短板，你在网上搜到的很多消息队列的对比文章还在说 Kafka 不可靠，其实这种说法早已经过时了。**当下的 Kafka 已经发展为一个非常成熟的消息队列产品，无论在数据可靠性、稳定性和功能特性等方面都可以满足绝大多数场景的需求**。

**Kafka 与周边生态系统的兼容性是最好的没有之一，尤其在大数据和流计算领域，几乎所有的相关开源软件系统都会优先支持 Kafka。**

Kafka 使用 Scala 和 Java 语言开发，设计上大量使用了 **批量** 和 **异步** 的思想，这种设计使得 Kafka 能做到超高的性能。Kafka 的性能，尤其是异步收发的性能，是三者中最好的，但与 RocketMQ 并没有量级上的差异，**大约每秒钟可以处理几十万条消息**。

我曾经使用配置比较好的服务器对 Kafka 进行过压测，在有足够的客户端并发进行异步批量发送，并且开启压缩的情况下，**Kafka 的极限处理能力可以超过每秒 2000 万条消息**。

但是 Kafka 这种异步批量的设计带来的问题是，**它的同步收发消息的响应时延比较高**，因为当客户端发送一条消息的时候，Kafka 并不会立即发送出去，而是要等一会儿攒一批再发送，在它的 Broker 中，很多地方都会使用这种“先攒一波再一起处理”的设计。当你的业务场景中，每秒钟消息数量没有那么多的时候，Kafka 的时延反而会比较高。所以，**Kafka 不太适合在线业务场景。**



### 3. 第二梯队的消息队列

除了上面给你介绍的三大消息队列之外，还有几个第二梯队的产品，我个人的观点是，这些产品之所以没那么流行，或多或少都有着比较明显的短板，不推荐使用。在这儿呢，我简单介绍一下，纯当丰富你的知识广度。

先说 `ActiveMQ`，`ActiveMQ` 是最老牌的开源消息队列，是十年前唯一可供选择的开源消息队列，目前已进入老年期，社区不活跃。无论是功能还是性能方面，ActiveMQ 都与现代的消息队列存在明显的差距，它存在的意义仅限于兼容那些还在用的爷爷辈儿的系统。

接下来说说 `ZeroMQ`，严格来说 ZeroMQ 并不能称之为一个消息队列，而是一个基于消息队列的多线程网络库，如果你的需求是 **将消息队列的功能集成到你的系统进程中**，可以考虑使用 ZeroMQ。

最后说一下 `Pulsar`，很多人可能都没听说过这个产品，Pulsar 是一个新兴的开源消息队列产品，最早是由 Yahoo 开发，目前处于成长期，流行度和成熟度相对没有那么高。与其他消息队列最大的不同是，`Pulsar` **采用存储和计算分离的设计**，我个人非常喜欢这种设计，它有可能会引领未来消息队列的一个发展方向，建议你持续关注这个项目。



### 4. 总结

在了解了上面这些开源消息队列各自的特点和优劣势后，我相信你对于消息队列的选择已经可以做到心中有数了。我也总结了几条选择的建议供你参考。

如果说，**消息队列并不是你将要构建系统的主角之一，你对消息队列功能和性能都没有很高的要求**，只需要一个开箱即用易于维护的产品，我建议你使用 `RabbitMQ`。

如果你的系统使用消息队列主要场景是**处理在线业务**，比如在交易系统中用消息队列传递订单，那 `RocketMQ` 的低延迟和金融级的稳定性是你需要的。

如果你需要 **处理海量的消息**，像收集日志、监控信息或是前端的埋点这类数据，或是你的应用场景大量使用了大数据、流计算相关的开源产品，那 Kafka 是最适合你的消息队列。

如果我说的这些场景和你的场景都不符合，你看了我之前介绍的这些消息队列的特点后，还是不知道如何选择，那就选你最熟悉的吧，毕竟这些产品都能满足大多数应用场景，使用熟悉的产品还可以快速上手不是？



## 03 消息模型: 主题和队列有什么区别？

这节课我们来学习消息队列中像 **队列**、**主题**、**分区** 等基础概念。这些基础的概念，就像我们学习一门编程语言中的基础语法一样，你只有搞清楚它们，才能进行后续的学习。



如果你研究过超过一种消息队列产品，你可能已经发现，每种消息队列都有自己的一套消息模型，像 **队列（Queue）**、**主题（Topic）**或是 **分区（Partition）**这些名词概念，在每个消息队列模型中都会涉及一些，含义还不太一样。

为什么出现这种情况呢？因为 **没有标准**。曾经，也是有一些国际组织尝试制定过消息相关的标准，比如早期的 `JMS` 和 `AMQP`。但让人无奈的是，标准的进化跟不上消息队列的演进速度，这些标准实际上已经被废弃了。

那么，到底什么是队列？什么是主题？主题和队列又有什么区别呢？想要彻底理解这些，我们需要从消息队列的演进说起。



### 1. 主题和队列有什么区别？

在互联网的架构师圈儿中间，流传着这样一句不知道出处的名言，我非常认同和喜欢：**好的架构不是设计出来的，而是演进出来的**。 现代的消息队列呈现出的模式，一样是经过之前的十几年逐步演进而来的。

最初的消息队列，就是一个严格意义上的队列。在计算机领域，**“队列（Queue）”** 是一种数据结构，有完整而严格的定义。在维基百科中，队列的定义是这样的：

队列是 **先进先出**（FIFO, First-In-First-Out）的 **线性表**（Linear List）。在具体应用中通常用链表或者数组来实现。**队列只允许在后端（称为 rear）进行插入操作，在前端（称为 front）进行删除操作**。



这个定义里面包含几个关键点，第一个是先进先出，这里面隐含着的一个要求是，在消息入队出队过程中，需要保证这些消息 **严格有序**，按照什么顺序写进队列，必须按照同样的顺序从队列中读出来。不过，队列是没有“读”这个操作的，“读”就是出队，也就是从队列中“删除”这条消息。

**早期的消息队列，就是按照 “队列” 的数据结构来设计的。**我们一起看下这个图，生产者（Producer）发消息就是入队操作，消费者（Consumer）收消息就是出队也就是删除操作，服务端存放消息的容器自然就称为“队列”。

这就是最初的一种消息模型：**队列模型**。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716045848992-acb74010-0d25-4513-88c8-6acf1bef8263.webp" alt="image.png" style="zoom:15%;" />

如果有多个生产者往同一个队列里面发送消息，这个队列中可以消费到的消息，就是这些生产者生产的所有消息的合集。消息的顺序就是这些生产者发送消息的自然顺序。如果有多个消费者接收同一个队列的消息，这些消费者之间实际上是竞争的关系，**每个消费者只能收到队列中的一部分消息**，也就是说任何一条消息只能被其中的一个消费者收到。

如果需要将一份消息数据分发给多个消费者，要求每个消费者都能收到全量的消息，例如，对于一份订单数据，风控系统、分析系统、支付系统等都需要接收消息。这个时候，单个队列就满足不了需求，一个可行的解决方式是，为每个消费者创建一个单独的队列，让生产者发送多份。

显然这是个比较蠢的做法，同样的一份消息数据被复制到多个队列中会浪费资源，更重要的是，生产者必须知道有多少个消费者。为每个消费者单独发送一份消息，这实际上违背了消息队列“解耦”这个设计初衷。

为了解决这个问题，演化出了另外一种消息模型：“**发布 - 订阅模型（Publish-Subscribe Pattern）**”。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716045848968-e4e0cd8d-c4db-403a-a2e3-fe09360eaa07.webp" alt="img" style="zoom:15%;" />

在 **发布 - 订阅模型** 中，消息的发送方称为 **发布者（Publisher）**，消息的接收方称为 **订阅者（Subscriber）**，服务端存放消息的容器称为 **主题（Topic）**。发布者将消息发送到主题中，订阅者在接收消息之前需要先“订阅主题”。“订阅”在这里既是一个动作，同时还可以认为是主题在消费时的一个逻辑副本，每份订阅中，订阅者都可以接收到主题的所有消息。

在消息领域的历史上很长的一段时间，**队列模式** 和 **发布 - 订阅模式** 是并存的，有些消息队列同时支持这两种消息模型，比如 ActiveMQ。我们仔细对比一下这两种模型，生产者就是发布者，消费者就是订阅者，队列就是主题，并没有本质的区别。**它们最大的区别其实就是，一份消息数据能不能被消费多次的问题。**

实际上，在这种发布 - 订阅模型中，如果只有一个订阅者，那它和队列模型就基本是一样的了。也就是说，发布 - 订阅模型在功能层面上是可以兼容队列模型的。

现代的消息队列产品使用的消息模型大多是这种发布 - 订阅模型，当然也有例外。



### 2. RabbitMQ 的消息模型

这个例外就是 RabbitMQ，它是少数依然坚持使用队列模型的产品之一。那它是怎么解决多个消费者的问题呢？你还记得我在上节课中讲到 RabbitMQ 的一个特色 **Exchange 模块** 吗？在 RabbitMQ 中，**Exchange 位于生产者和队列之间**，生产者并不关心将消息发送给哪个队列，而是将消息发送给 Exchange，**由 Exchange 上配置的策略来决定将消息投递到哪些队列中**。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716046183716-2cabf6b9-9d6f-468a-ab26-0341295fd9eb.webp" alt="img" style="zoom:15%;" />

同一份消息如果需要被多个消费者来消费，**需要配置 Exchange 将消息发送到多个队列**，每个队列中都存放一份完整的消息数据，可以为一个消费者提供消费服务。这也可以变相地实现新发布 - 订阅模型中，“一份消息数据可以被多个订阅者来多次消费”这样的功能。具体的配置你可以参考 RabbitMQ 官方教程，其中一个章节专门是讲如何实现发布订阅的。

### 3. RocketMQ 的消息模型

讲完了 `RabbitMQ` 的消息模型，我们再来看看 `RocketMQ`。`RocketMQ` 使用的消息模型是 **标准的发布 - 订阅模型**，在 RocketMQ 的术语表中，生产者、消费者和主题与我在上面讲的发布 - 订阅模型中的概念是完全一样的。

但是，在 RocketMQ 也有 **队列（Queue）**这个概念，并且队列在 RocketMQ 中是一个非常重要的概念，那 **队列在 RocketMQ 中的作用是什么呢？**这就要从消息队列的消费机制说起。

几乎所有的消息队列产品都使用一种非常朴素的 **“请求 - 确认” 机制**，确保消息不会在传递过程中由于网络或服务器故障丢失。具体的做法也非常简单。在生产端，生产者先将消息发送给服务端，也就是 Broker，服务端在收到消息并将消息写入主题或者队列中后，会给生产者发送确认的响应。

如果生产者没有收到服务端的确认或者收到失败的响应，则会重新发送消息；在消费端，消费者在收到消息并完成自己的消费业务逻辑（比如，将数据保存到数据库中）后，也会给服务端发送消费成功的确认，服务端只有收到消费确认后，才认为一条消息被成功消费，否则它会给消费者重新发送这条消息，直到收到对应的消费成功确认。

这个确认机制很好地保证了消息传递过程中的 **可靠性**，但是，引入这个机制在消费端带来了一个不小的问题。什么问题呢？为了确保消息的有序性，在某一条消息被成功消费之前，下一条消息是不能被消费的，否则就会出现**消息空洞**，违背了 **有序性** 这个原则。

也就是说，每个主题在任意时刻，至多只能有一个消费者实例在进行消费，那就没法通过水平扩展消费者的数量来提升消费端总体的消费性能。为了解决这个问题，RocketMQ 在主题下面增加了队列的概念。

**每个主题包含多个队列，通过多个队列来实现多实例并行生产和消费。**需要注意的是，RocketMQ 只在队列上保证消息的有序性，主题层面是无法保证消息的严格顺序的。

RocketMQ 中，订阅者的概念是通过消费组（Consumer Group）来体现的。每个消费组都消费主题中一份完整的消息，不同消费组之间消费进度彼此不受影响，也就是说，一条消息被 Consumer Group1 消费过，也会再给 Consumer Group2 消费。

消费组中包含多个消费者，同一个组内的消费者是竞争消费的关系，每个消费者负责消费组内的一部分消息。如果一条消息被消费者 Consumer1 消费了，那同组的其他消费者就不会再收到这条消息。

在 Topic 的消费过程中，由于消息需要被不同的组进行多次消费，所以消费完的消息并不会立即被删除，这就需要 RocketMQ 为每个消费组在每个队列上维护一个消费位置（Consumer Offset），这个位置之前的消息都被消费过，之后的消息都没有被消费过，每成功消费一条消息，消费位置就加一。这个消费位置是非常重要的概念，我们在使用消息队列的时候，丢消息的原因大多是由于消费位置处理不当导致的。

RocketMQ 的消息模型中，比较关键的概念就是这些了。为了便于你理解，我画了下面这张图：

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716046355152-094e7820-cacd-4cd2-b251-82aaf68000cf.webp" alt="img" style="zoom:15%;" />

你可以对照这张图再把我刚刚讲的这些概念继续消化一下，加深理解。

### 4. Kafka 的消息模型

我们再来看看另一种常见的消息队列 Kafka，Kafka 的消息模型和 RocketMQ 是完全一样的，我刚刚讲的所有 RocketMQ 中对应的概念，和生产消费过程中的确认机制，都完全适用于 Kafka。唯一的区别是，在 Kafka 中，队列这个概念的名称不一样，Kafka 中对应的名称是 “**分区（Partition）**”，含义和功能是没有任何区别的。



### 5. 小结

我们来总结一下本节课学习的内容。首先我们讲了队列和主题的区别，这两个概念的背后实际上对应着两种不同的消息模型：**队列模型** 和 **发布 - 订阅模型**。然后你需要理解，这两种消息模型其实并没有本质上的区别，都可以通过一些扩展或者变化来互相替代。

常用的消息队列中，RabbitMQ 采用的是队列模型，但是它一样可以实现发布 - 订阅的功能。RocketMQ 和 Kafka 采用的是发布 - 订阅模型，并且二者的消息模型是基本一致的。

最后提醒你一点，我这节课讲的消息模型和相关的概念是业务层面的模型，深刻理解业务模型有助于你用最佳的姿势去使用消息队列。

但业务模型不等于就是实现层面的模型。比如说 MySQL 和 Hbase 同样是支持 SQL 的数据库，它们的业务模型中，存放数据的单元都是“表”，但是在实现层面，没有哪个数据库是以二维表的方式去存储数据的，MySQL 使用 B+ 树来存储数据，而 HBase 使用的是 KV 的结构来存储。同样，像 Kafka 和 RocketMQ 的业务模型基本是一样的，并不是说他们的实现就是一样的，实际上这两个消息队列的实现是完全不同的。



### 6. 思考题

最后给大家留一个思考题。刚刚我在介绍 RocketMQ 的消息模型时讲过，在消费的时候，为了保证消息的不丢失和严格顺序，每个队列只能串行消费，无法做到并发，否则会出现消费空洞的问题。那如果放宽一下限制，不要求严格顺序，能否做到单个队列的并行消费呢？如果可以，该如何实现？



## 04 如何利用事务消息实现分布式事务？



一说起事务，你可能自然会联想到数据库。的确，我们日常使用事务的场景，绝大部分都是在操作数据库的时候。像 MySQL、Oracle 这些主流的关系型数据库，也都提供了完整的事务实现。那消息队列为什么也需要事务呢？

其实很多场景下，我们“发消息”这个过程，目的往往是通知另外一个系统或者模块去更新数据，**消息队列中的“事务”，主要解决的是消息生产者和消息消费者的数据一致性问题。**

依然拿我们熟悉的电商来举个例子。一般来说，用户在电商 APP 上购物时，先把商品加到购物车里，然后几件商品一起下单，最后支付，完成购物流程，就可以愉快地等待收货了。

这个过程中有一个需要用到消息队列的步骤，订单系统创建订单后，发消息给购物车系统，将已下单的商品从购物车中删除。因为从购物车删除已下单商品这个步骤，并不是用户下单支付这个主要流程中必需的步骤，使用消息队列来异步清理购物车是更加合理的设计。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716190763541-dc87544a-f986-4c6a-bd24-230c695d9851.png" alt="img" style="zoom:20%;" />



对于订单系统来说，它创建订单的过程中实际上执行了 2 个步骤的操作：

1. 在订单库中插入一条订单数据，创建订单；
2. 发消息给消息队列，消息的内容就是刚刚创建的订单。

购物车系统订阅相应的主题，接收订单创建的消息，然后清理购物车，在购物车中删除订单中的商品。

在分布式系统中，上面提到的这些步骤，任何一个步骤都有可能失败，如果不做任何处理，那就有可能出现订单数据与购物车数据不一致的情况，比如说：

- 创建了订单，没有清理购物车；
- 订单没创建成功，购物车里面的商品却被清掉了。



那我们需要解决的问题可以总结为：**在上述任意步骤都有可能失败的情况下，还要保证订单库和购物车库这两个库的数据一致性。**

对于购物车系统收到订单创建成功消息清理购物车这个操作来说，失败的处理比较简单，只要成功执行购物车清理后再提交消费确认即可，如果失败，由于没有提交消费确认，消息队列会自动重试。

问题的关键点集中在订单系统，**创建订单和发送消息这两个步骤要么都操作成功，要么都操作失败**，不允许一个成功而另一个失败的情况出现。

这就是事务需要解决的问题。



### 1. 什么是分布式事务？

那什么是事务呢？如果我们需要对若干数据进行更新操作，为了保证这些数据的完整性和一致性，我们希望这些更新操作 **要么都成功，要么都失败。**至于更新的数据，不只局限于数据库中的数据，可以是磁盘上的一个文件，也可以是远端的一个服务，或者以其他形式存储的数据。

这就是通常我们理解的事务。其实这段对事务的描述不是太准确也不完整，但是，它更易于理解，大体上也是正确的。所以我还是倾向于这样来讲“事务”这个比较抽象的概念。

一个严格意义的事务实现，应该具有 4 个属性：原子性、一致性、隔离性、持久性。这四个属性通常称为 **ACID 特性**。

1. **原子性**，是指一个事务操作不可分割，要么成功，要么失败，不能有一半成功一半失败的情况。
2. **一致性**，是指这些数据在事务执行完成这个时间点之前，读到的一定是更新前的数据，之后读到的一定是更新后的数据，不应该存在一个时刻，让用户读到更新过程中的数据。
3. **隔离性**，是指一个事务的执行不能被其他事务干扰。即一个事务内部的操作及使用的数据对正在进行的其他事务是隔离的，并发执行的各个事务之间不能互相干扰，这个有点儿像我们打网游中的副本，我们在副本中打的怪和掉的装备，与其他副本没有任何关联也不会互相影响。
4. **持久性**，是指一个事务一旦完成提交，后续的其他操作和故障都不会对事务的结果产生任何影响。



大部分传统的单体关系型数据库都完整的实现了 `ACID`，但是，对于分布式系统来说，严格的实现 ACID 这四个特性几乎是不可能的，或者说实现的代价太大，大到我们无法接受。

分布式事务就是要在分布式系统中的实现事务。在分布式系统中，在保证可用性和不严重牺牲性能的前提下，光是要实现数据的一致性就已经非常困难了，所以出现了很多“残血版”的一致性，比如 **顺序一致性**、**最终一致性** 等等。

显然实现严格的分布式事务是更加不可能完成的任务。所以，目前大家所说的分布式事务，更多情况下，是在**分布式系统中事务的不完整实现**。在不同的应用场景中，有不同的实现，目的都是通过一些妥协来解决实际问题。

在实际应用中，比较常见的分布式事务实现有 **2PC（Two-phase Commit，也叫二阶段提交）**、**TCC(Try-Confirm-Cancel)** 和 **事务消息**。每一种实现都有其特定的使用场景，也有各自的问题，都不是完美的解决方案。

**事务消息** 适用的场景主要是那些需要异步更新数据，并且对数据实时性要求不太高的场景。比如我们在开始时提到的那个例子，在创建订单后，如果出现短暂的几秒，购物车里的商品没有被及时清空，也不是完全不可接受的，只要最终购物车的数据和订单数据保持一致就可以了。

**2PC** 和 **TCC** 不是我们本次课程讨论的内容，就不展开讲了，感兴趣的同学可以自行学习。



### 2. 消息队列是如何实现分布式事务的？

事务消息需要消息队列提供相应的功能才能实现，`Kafka` 和 `RocketMQ` 都提供了事务相关功能。

回到订单和购物车这个例子，我们一起来看下如何用消息队列来实现分布式事务。

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716191665775-378d2933-cea8-454b-8763-a7d9210edbae.webp" alt="img" style="zoom:15%;" />

**首先**，订单系统在消息队列上开启一个事务。然后订单系统给消息服务器发送一个 **“半消息”**，这个半消息不是说消息内容不完整，它 **包含的内容就是完整的消息内容**，半消息和普通消息的唯一区别是，**在事务提交之前，对于消费者来说，这个消息是不可见的**。

半消息发送成功后，订单系统就可以执行本地事务了，在订单库中创建一条订单记录，并提交订单库的数据库事务。然后根据本地事务的执行结果决定 **提交或者回滚** 事务消息。如果订单创建成功，那就提交事务消息，购物车系统就可以消费到这条消息继续后续的流程。如果订单创建失败，那就回滚事务消息，购物车系统就不会收到这条消息。这样就基本实现了“要么都成功，要么都失败”的一致性要求。

如果你足够细心，可能已经发现了，这个实现过程中，有一个问题是没有解决的。如果 **在第四步提交事务消息时失败了怎么办？**对于这个问题，Kafka 和 RocketMQ 给出了 2 种不同的解决方案。

Kafka 的解决方案比较简单粗暴，**直接抛出异常**，让用户自行处理。我们可以在业务代码中反复重试提交，直到提交成功，或者删除之前创建的订单进行补偿。RocketMQ 则给出了另外一种解决方案。



### 3. RocketMQ 中的分布式事务实现

在 `RocketMQ` 中的事务实现中，增加了 **事务反查的机制** 来解决事务消息提交失败的问题。如果 Producer 也就是订单系统，在提交或者回滚事务消息时发生网络异常，RocketMQ 的 Broker 没有收到提交或者回滚的请求，Broker 会定期去 Producer 上 **反查这个事务对应的本地事务的状态**，然后根据反查结果决定提交或者回滚这个事务。

为了支撑这个事务反查机制，我们的业务代码需要实现一个 **反查本地事务状态的接口**，告知 RocketMQ 本地事务是成功还是失败。

在我们这个例子中，反查本地事务的逻辑也很简单，我们只要根据消息中的订单 ID，在订单库中查询这个订单是否存在即可，如果订单存在则返回成功，否则返回失败。RocketMQ 会自动根据事务反查的结果提交或者回滚事务消息。

这个反查本地事务的实现，并不依赖消息的发送方，也就是订单服务的某个实例节点上的任何数据。这种情况下，即使是发送事务消息的那个订单服务节点宕机了，RocketMQ 依然可以通过其他订单服务的节点来执行反查，确保事务的完整性。

综合上面讲的通用事务消息的实现和 RocketMQ 的事务反查机制，使用 RocketMQ 事务消息功能实现分布式事务的流程如下图：

<img src="../media/2024-06-24-%E6%B6%88%E6%81%AF%E9%98%9F%E5%88%97/1716192007649-82f28468-f687-4fc2-8928-845520dbf2c6.png" alt="img" style="zoom:20%;" />

### 4. 小结

我们通过一个订单购物车的例子，学习了事务的 `ACID` 四个特性，以及如何使用消息队列来实现分布式事务。

然后我们给出了现有的几种分布式事务的解决方案，包括事务消息，但是这几种方案都不能解决分布式系统中的所有问题，每一种方案都有局限性和特定的适用场景。

最后，我们一起学习了 RocketMQ 的事务反查机制，这种机制通过定期反查事务状态，来补偿提交事务消息可能出现的通信失败。在 Kafka 的事务功能中，并没有类似的反查机制，需要用户自行去解决这个问题。

但是，这不代表 RocketMQ 的事务功能比 Kafka 更好，只能说在我们这个例子的场景下，更适合使用 RocketMQ。Kafka 对于事务的定义、实现和适用场景，和 RocketMQ 有比较大的差异，后面的课程中，我们会专门讲到 Kafka 的事务的实现原理。



### 5. 思考题

课后，我建议你最好能通过写代码的方式，把我们这节课中的订单购物车的例子，用 RocketMQ 完整地实现出来。然后再思考一下，RocketMQ 的这种事务消息是不是完整地实现了事务的 ACID 四个特性？如果不是，哪些特性没有实现？



## 05 如何确保消息不会丢失?









